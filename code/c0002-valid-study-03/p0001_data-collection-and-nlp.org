#+title: P0001_data Collection

#+PROPERTY: header-args:jupyter-python  :tangle   yes
#+PROPERTY: header-args:jupyter-python  :tangle   no

#+PROPERTY: header-args:jupyter-python+ :shebang  "#!/usr/bin/env ipython\n# -*- coding: utf-8 -*-\n\n"
#+PROPERTY: header-args:jupyter-python+ :eval     yes
#+PROPERTY: header-args:jupyter-python+ :comments org
#+PROPERTY: header-args:jupyter-python+ :results  raw drawer pp
#+PROPERTY: header-args:jupyter-python+ :exports  both
#+PROPERTY: header-args:jupyter-python+ :async    yes

#+PROPERTY: header-args:jupyter-python+ :session  python3 :kernel python3
#+PROPERTY: header-args:jupyter-python+ :session  remote_fast8_jiko_at_buka2 :kernel remote_fast8_jiko_at_buka2
#+PROPERTY: header-args:jupyter-python+ :session  local_fast8 :kernel local_fast8


* Boilerplate
** test: Remote on buka2
#+begin_src emacs-lisp :tangle no :eval no
(find-file "/ssh:jiko@buka2:/home/jiko/cc/dev/c2023a/c0501_bertagent_devel/code/p0003_valid-03-part-001-supernatural/")
#+end_src

** test: Logger and Location
#+begin_src jupyter-python :async yes :tangle no
import nvm
import srsly
import pathlib
logZ = nvm.Log0()
log0 = logZ.logger
locations = """
stardust7:
  jiko: cc/dev/c2023a/c0501_bertagent_devel/code/p0003_valid-03-part-001-supernatural/
buka2:
  jiko: cc/dev/c2023a/c0501_bertagent_devel/code/p0003_valid-03-part-001-supernatural/
"""
locations = srsly.yaml_loads(locations)
log0.info(f"{nvm.chdir(locations)}")
#+end_src

** test: Auto reload
#+begin_src jupyter-python :async yes
get_ipython().run_line_magic("load_ext", "autoreload")
get_ipython().run_line_magic("autoreload", "2")
#+end_src

#+RESULTS:

* Imports
** prod: NVM
#+begin_src jupyter-python :async yes
from nvm import disp_df
from nvm import repr_df
from nvm import rdf
from nvm import ddf
from nvm import clean_str
from nvm.aux_str import CLEAN_STR_MAPPINGS_LARGE as maps0
from nvm.aux_str import REGEX_ABC_DASH_XYZ_ASTERISK as re0
from nvm.aux_pandas import fix_column_names
#+end_src

#+RESULTS:

** prod: Basics
#+begin_src jupyter-python :async yes
import os
import pathlib
import numpy as np
import pandas as pd
import re
import json
import yaml
import srsly
import uuid
import random
import numbers
from collections import OrderedDict
from contextlib import ExitStack
import warnings
# warnings.warn("\nwarning")
from hashlib import md5
import humanfriendly as hf
import time
import datetime as dt
from pytz import timezone as tz
tz0 = tz("Europe/Berlin")
from glob import glob
from tqdm import tqdm
import logging
log0.info("DONE: basic imports")
#+end_src

#+RESULTS:
: I: DONE: basic imports

** prod: Extra imports and settings
#+begin_src jupyter-python :async yes
from contexttimer import Timer
import textwrap

HOME = pathlib.Path.home()

tqdm.pandas()

import matplotlib
from matplotlib import pyplot as plt
# import seaborn as sns
# import plotly.graph_objects as go
# import plotly.express as px

# get_ipython().run_line_magic("matplotlib", "qt")
# get_ipython().run_line_magic("matplotlib", "inline")

with Timer() as elapsed:
    time.sleep(0.001)

log0.info(hf.format_timespan(elapsed.elapsed))

log0.info("DONE: extra imports and settings")
#+end_src

#+RESULTS:
#+begin_example
I: 0 seconds
I: DONE: extra imports and settings
#+end_example

* Extra Imports
** prod: More extra imports and settings
#+begin_src jupyter-python :async yes

log0.info("DONE: more extra imports and settings")
#+end_src

#+RESULTS:
: I: DONE: more extra imports and settings

* Notes
** test: Local
** test: Remote
* SpaCy
** prod: Imports
#+begin_src jupyter-python :async yes
import spacy
from spacy.tokens import Doc, Span, Token
from spacy.tokens.underscore import Underscore
from dframcy import DframCy
from nvm.aux_spacy import get_doc_count_of_dict_items_component
from nvm.aux_spacy import get_doc_basic_metrics_component
from nvm.aux_spacy import get_doc_word_count_component
from nvm.aux_spacy import get_doc_sentences_as_list_component
from nvm.aux_spacy import get_doc_summary_dict_component

from nvm.aux_spacy.data.data_big2 import big2_dict
from nvm.aux_spacy.data.data_nico import nico_dict

Underscore.doc_extensions = {}
Underscore.span_extensions = {}
Underscore.token_extensions = {}

log0.info("DONE: spacy imports")
#+end_src

#+RESULTS:
: I: DONE: spacy imports

** prod: Setup NLP
#+begin_src jupyter-python :async yes
nlp = spacy.load("en_core_web_sm")
# nlp = spacy.load("en_core_web_lg")

nlp.tokenizer.add_special_case("cannot", [{spacy.symbols.ORTH: "cannot"}])
if not Doc.has_extension("index0"):
    Doc.set_extension("index0", default=None)

# config1 = dict(dict0=liwc_dict)
config2 = dict(dict0=big2_dict)
# config3 = dict(
#     dict0={key0: gen_inq_lcm_dict[key0] for key0 in ["IAV", "DAV", "SV"]},
#     pos=["VERB"])

# config4 = dict(
#     dict0={key0: gen_inq_lcm_dict[key0] for key0 in ["IPadj", "IndAdj"]},
#     pos=["ADJ"])

# config5 = dict(dict0=gaucher_dict)
# config6 = dict(dict0=madera_dict)
config7 = dict(dict0=nico_dict)
# config8 = dict(dict0=big2_liwc_dict)
# config9 = dict(dict0=gen_inq_cat_dict)

nlp.add_pipe("get_doc_word_count", "WC")
# nlp.add_pipe("get_doc_pron_count", "PC")
nlp.add_pipe("get_doc_sentences_as_list", "SENTS")
nlp.add_pipe("get_doc_basic_metrics", "BASIC")
# nlp.add_pipe("get_doc_big2a_ag_count", "big2a_ag")
# nlp.add_pipe("get_doc_POS_count_as_dict", "POS")
# nlp.add_pipe("get_doc_TAG_count_as_dict", "TAG")
nlp.add_pipe("get_doc_count_of_dict_items", "big2", config=config2)
# nlp.add_pipe("get_doc_count_of_dict_items", "lcm0", config=config3)
# nlp.add_pipe("get_doc_count_of_dict_items", "lcm1", config=config4)

# nlp.add_pipe("get_doc_count_of_dict_items", "gaucher", config=config5)
# nlp.add_pipe("get_doc_count_of_dict_items", "madera", config=config6)
nlp.add_pipe("get_doc_count_of_dict_items", "nico", config=config7)
# nlp.add_pipe("get_doc_count_of_dict_items", "gen_inq_cats", config=config9)
# nlp.add_pipe("get_doc_count_of_dict_items", "big2_liwc", config=config8)

# nlp.add_pipe("get_doc_count_of_dict_items", "liwc", config=config1)

# nlp.add_pipe("concr", "CONCR")

nlp.add_pipe("get_doc_summary_dict", "SUMMARY")  # CAUTION: This should be the last one TODO FIXME add parameter as well

log0.info("DONE: nlp setup")
#+end_src

#+RESULTS:
: I: DONE: nlp setup
** prod: Checkup
#+begin_src jupyter-python :async yes
tok_exts = list(Underscore.token_extensions.keys())
spn_exts = list(Underscore.span_extensions.keys())
doc_exts = list(Underscore.doc_extensions.keys())

log0.info(f"{doc_exts = }")
log0.info(f"{spn_exts = }")
log0.info(f"{tok_exts = }")
log0.info(f"{nlp.pipe_names = }")
#+end_src

#+RESULTS:
#+begin_example
I: doc_exts = ['index0', 'word_count', 'sents', 'WORD_count', 'NOUN_count', 'ADJ_count', 'VERB_count', 'VERB_count_without_be_and_have', 'VB_count', 'VB_count_without_be_and_have', 'JJ_count', 'JJRs_count', 'JJSs_count', 'count_of_is_big2c_agen_from_big2', 'count_of_is_big2a_agen_from_big2', 'count_of_is_big2a_comm_from_big2', 'count_of_is_big2b_agen_from_big2', 'count_of_is_big2b_comm_from_big2', 'count_of_is_nico_full_ability_posit_from_nico', 'count_of_is_nico_full_status_negat_from_nico', 'count_of_is_nico_seed_ability_negat_from_nico', 'count_of_is_nico_full_agency_posit_from_nico', 'count_of_is_nico_seed_agency_posit_from_nico', 'count_of_is_nico_seed_agency_negat_from_nico', 'count_of_is_nico_full_ability_negat_from_nico', 'count_of_is_nico_seed_ability_posit_from_nico', 'count_of_is_nico_full_agency_negat_from_nico', 'count_of_is_nico_full_status_posit_from_nico', 'count_of_is_nico_seed_status_negat_from_nico', 'count_of_is_nico_seed_status_posit_from_nico', 'SUMMARY']
I: spn_exts = []
I: tok_exts = ['is_VB', 'is_VB_without_be_and_have', 'is_big2c_agen_from_big2', 'is_big2a_agen_from_big2', 'is_big2a_comm_from_big2', 'is_big2b_agen_from_big2', 'is_big2b_comm_from_big2', 'is_nico_full_ability_posit_from_nico', 'is_nico_full_status_negat_from_nico', 'is_nico_seed_ability_negat_from_nico', 'is_nico_full_agency_posit_from_nico', 'is_nico_seed_agency_posit_from_nico', 'is_nico_seed_agency_negat_from_nico', 'is_nico_full_ability_negat_from_nico', 'is_nico_seed_ability_posit_from_nico', 'is_nico_full_agency_negat_from_nico', 'is_nico_full_status_posit_from_nico', 'is_nico_seed_status_negat_from_nico', 'is_nico_seed_status_posit_from_nico']
I: nlp.pipe_names = ['tok2vec', 'tagger', 'parser', 'senter', 'attribute_ruler', 'lemmatizer', 'ner', 'WC', 'SENTS', 'BASIC', 'big2', 'nico', 'SUMMARY']
#+end_example

** prod: Checkup
#+begin_src jupyter-python :async yes
for name0 in nlp.pipe_names:
    print(f"    \"{name0}\",")
#+end_src

#+RESULTS:
#+begin_example
    "tok2vec",
    "tagger",
    "parser",
    "senter",
    "attribute_ruler",
    "lemmatizer",
    "ner",
    "WC",
    "SENTS",
    "BASIC",
    "big2",
    "nico",
    "SUMMARY",
#+end_example

** prod: Checkup
#+begin_src jupyter-python :async yes
for ext0 in doc_exts:
    print(f"    \"{ext0}\",")
#+end_src

#+RESULTS:
#+begin_example
    "index0",
    "word_count",
    "sents",
    "WORD_count",
    "NOUN_count",
    "ADJ_count",
    "VERB_count",
    "VERB_count_without_be_and_have",
    "VB_count",
    "VB_count_without_be_and_have",
    "JJ_count",
    "JJRs_count",
    "JJSs_count",
    "count_of_is_big2c_agen_from_big2",
    "count_of_is_big2a_agen_from_big2",
    "count_of_is_big2a_comm_from_big2",
    "count_of_is_big2b_agen_from_big2",
    "count_of_is_big2b_comm_from_big2",
    "count_of_is_nico_full_ability_posit_from_nico",
    "count_of_is_nico_full_status_negat_from_nico",
    "count_of_is_nico_seed_ability_negat_from_nico",
    "count_of_is_nico_full_agency_posit_from_nico",
    "count_of_is_nico_seed_agency_posit_from_nico",
    "count_of_is_nico_seed_agency_negat_from_nico",
    "count_of_is_nico_full_ability_negat_from_nico",
    "count_of_is_nico_seed_ability_posit_from_nico",
    "count_of_is_nico_full_agency_negat_from_nico",
    "count_of_is_nico_full_status_posit_from_nico",
    "count_of_is_nico_seed_status_negat_from_nico",
    "count_of_is_nico_seed_status_posit_from_nico",
    "SUMMARY",
#+end_example
* Process
** prod: Load data
#+begin_src jupyter-python :async yes
dir0 = "../../data/v0003_supernatural/SommerEtAl2022a/"
dir0 = pathlib.Path(dir0)
# dir0.mkdir(mode=0o700, parents=True, exist_ok=True)
assert dir0.exists(), f"The data directory dir0={str(dir0)} not found!"

name0 = f"data_text_with_evals"
extn0 = ".pkl"

if0 = (dir0/name0).with_suffix(extn0)
log0.info(f"loading: {if0}...")
df0 = pd.read_pickle(if0)
log0.info(f"loading: {if0}... DONE")

log0.info(f"{df0.shape = }")
disp_df(df0.sample(n=8).sort_index())
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
I: loading: ../../data/v0003_supernatural/SommerEtAl2022a/data_text_with_evals.pkl...
I: loading: ../../data/v0003_supernatural/SommerEtAl2022a/data_text_with_evals.pkl... DONE
I: df0.shape = (216, 10)
#+end_example
#+begin_example
     id0                                         text    useful  imageable  thought_provoking   unusual  intentional_agency  strategic_knowledge  acts_in_the_world  motivates_rituals
7      8  Stone that believes it is a hat and blee...  1.200000   2.500000           3.350000  4.400000            2.785714             2.428571           2.571429           1.571429
38    39  Cloud that is grey and full of rain and ...  2.750000   4.000000           2.000000  1.350000            1.307692             1.615385           3.076923           1.846154
49    50  Rabbit that is very fluffy to the touch ...  2.000000   4.588235           1.882353  1.235294            3.600000             2.800000           3.700000           2.100000
78    79     Icicle that has been spray painted green  1.473684   3.578947           1.947368  3.736842            1.000000             1.000000           2.076923           1.230769
82    83  Cactus whose interior is made of plastic...  1.388889   3.055556           2.277778  4.277778            1.363636             1.000000           1.454545           1.545455
110  111  Cloud that watches everything people do ...  3.000000   3.368421           3.631579  4.631579            4.500000             4.300000           4.400000           3.800000
121  122  Rabbit that is an advanced robot and has...  2.238095   2.523810           3.523810  4.761905            3.750000             3.833333           4.416667           3.583333
123  124             Person who can turn into animals  3.368421   3.789474           4.105263  4.052632            4.642857             4.642857           4.571429           4.214286
#+end_example
:END:
** prod: Prepare DOCS dictionary and list
#+begin_src jupyter-python :async yes
text_field = "text"

assert df0.index.is_unique, "Dataframe index must be unique before dictionary creation!"
txt_dict = df0[text_field].to_dict()
txt_list = [[val0, {"index0": key0}] for key0, val0 in txt_dict.items()]
assert len(df0) == len(txt_list)
assert len(df0) == len(txt_dict)

log0.info(f"{len(df0) = }")
log0.info(f"{len(txt_dict) = }")
log0.info(f"{len(txt_list) = }")
#+end_src

#+RESULTS:
#+begin_example
I: len(df0) = 216
I: len(txt_dict) = 216
I: len(txt_list) = 216
#+end_example
** test: Checkup
#+begin_src jupyter-python :async yes
idx0 = 0
idx0 = 3
log0.info(f"{txt_list[idx0] = }")

samp_size = 4
for item0 in random.sample(txt_dict.items(), samp_size):
    log0.info("- {}".format(item0))

samp_size = 4
for item0 in random.sample(txt_list, samp_size):
    log0.info("- {}".format(item0))

#+end_src

#+RESULTS:
#+begin_example
I: txt_list[idx0] = ['Lamp that likes to listen to vacuum cleaners', {'index0': 3}]
I: - (65, 'Cactus that likes to be eaten and is as old as the universe and slowly grows spines in areas where birds have sat recently')
I: - (54, 'Puddle that feels very angry')
I: - (58, 'Rocking chair that prays to Zeus and was born from a flower')
I: - (148, 'Lamp that is bright and can be dimmed')
I: - ['Person who can turn into animals and can communicate with animals', {'index0': 124}]
I: - ['Bird that sings in the morning and recently laid eggs', {'index0': 103}]
I: - ['Lamp that is bright', {'index0': 147}]
I: - ['Cactus that likes to be eaten and is as old as the universe', {'index0': 64}]
#+end_example

** prod: COMPUTE (NLP.PIPE)
#+begin_src jupyter-python :async yes
log0.info("Starting SpaCy NLP pipeline")
time_t0 = time.perf_counter()

doc_list = list(tqdm(
    nlp.pipe(txt_list, as_tuples=True),
    desc="DOC_LIST",
    total=len(txt_list),
    leave=True,
    disable=False,      # CONSIDER: turning that off for Emacs
    mininterval=0.250,
))
time_t1 = time.perf_counter()
time_d1 = time_t1-time_t0
log0.info(f"DONE: processed: {len(doc_list)} documents.")
log0.info(f"DONE: time elapsed: {hf.format_timespan(time_d1)}.")
#+end_src

#+RESULTS:
#+begin_example
I: Starting SpaCy NLP pipeline
DOC_LIST: 100% 216/216 [00:00<00:00, 547.41it/s]
I: DONE: processed: 216 documents.
I: DONE: time elapsed: 0.4 seconds.
#+end_example

** test: Checkup DOC example
#+begin_src jupyter-python :async yes
idx0 = 0
idx0 = 123
idx0 = 42
doc0, ctx0 = doc_list[idx0]
log0.info(f"{doc0._.index0 = }")
log0.info(f"{doc0._.WORD_count = }")
# log0.info(f"{doc0._.concr_mean = }")
log0.info(f"{doc0.text = }")
log0.info(f"{ctx0 = }")
for key0, val0 in doc0._.SUMMARY.items():
    log0.info(f"- {key0}: {val0}")

#+end_src

#+RESULTS:
#+begin_example
I: doc0._.index0 = None
I: doc0._.WORD_count = 5
I: doc0.text = 'Stone that is greyish brown'
I: ctx0 = {'index0': 42}
I: - index0: None
I: - word_count: 5
I: - sents: ['Stone that is greyish brown']
I: - WORD_count: 5
I: - NOUN_count: 2
I: - ADJ_count: 1
I: - VERB_count: 0
I: - VERB_count_without_be_and_have: 0
I: - VB_count: 0
I: - VB_count_without_be_and_have: 0
I: - JJ_count: 1
I: - JJRs_count: 0
I: - JJSs_count: 0
I: - count_of_is_big2c_agen_from_big2: 0
I: - count_of_is_big2a_agen_from_big2: 0
I: - count_of_is_big2a_comm_from_big2: 0
I: - count_of_is_big2b_agen_from_big2: 0
I: - count_of_is_big2b_comm_from_big2: 0
I: - count_of_is_nico_full_ability_posit_from_nico: 0
I: - count_of_is_nico_full_status_negat_from_nico: 0
I: - count_of_is_nico_seed_ability_negat_from_nico: 0
I: - count_of_is_nico_full_agency_posit_from_nico: 0
I: - count_of_is_nico_seed_agency_posit_from_nico: 0
I: - count_of_is_nico_seed_agency_negat_from_nico: 0
I: - count_of_is_nico_full_ability_negat_from_nico: 0
I: - count_of_is_nico_seed_ability_posit_from_nico: 0
I: - count_of_is_nico_full_agency_negat_from_nico: 0
I: - count_of_is_nico_full_status_posit_from_nico: 0
I: - count_of_is_nico_seed_status_negat_from_nico: 0
I: - count_of_is_nico_seed_status_posit_from_nico: 0
#+end_example

** prod: Produce output dictionary
#+begin_src jupyter-python :async yes
log0.info("Adding index0 to DOC)")
time_t0 = time.perf_counter()

out_dict = {}
for doc0, ctx0 in tqdm(
        doc_list,
        desc="OUT_DICT",
        total=len(doc_list),
        leave=True,
        disable=False,
        mininterval=0.50):
    index0 = ctx0["index0"]
    out_dict[index0] = doc0._.SUMMARY
    out_dict[index0]["index0"] = index0
    out_dict[index0] = {f"spacy_{key}": val for key, val in out_dict[index0].items()}
    # out_dict[index0]["text0"] = str(doc0.text)

time_t1 = time.perf_counter()
time_d1 = time_t1-time_t0
log0.info(f"DONE: processed: {len(out_dict)} documents.")
log0.info(f"DONE: out_dict time elapsed: {hf.format_timespan(time_d1)}.")

log0.info(f"TYPE: {type(out_dict)}.")
log0.info(f"TYPE: {type(out_dict[11])}.")
log0.info(f"EXAMPLE: {out_dict[11]}.")
#+end_src

#+RESULTS:
#+begin_example
I: Adding index0 to DOC)
OUT_DICT: 100% 216/216 [00:00<00:00, 184177.61it/s]
I: DONE: processed: 216 documents.
I: DONE: out_dict time elapsed: 0 seconds.
I: TYPE: <class 'dict'>.
I: TYPE: <class 'dict'>.
I: EXAMPLE: {'spacy_index0': 11, 'spacy_word_count': 24, 'spacy_sents': ['Tree that gets a year younger every other year and is made of lead under its bark and waves its branches when itâ€™s cloudy'], 'spacy_WORD_count': 24, 'spacy_NOUN_count': 6, 'spacy_ADJ_count': 3, 'spacy_VERB_count': 3, 'spacy_VERB_count_without_be_and_have': 3, 'spacy_VB_count': 0, 'spacy_VB_count_without_be_and_have': 0, 'spacy_JJ_count': 2, 'spacy_JJRs_count': 1, 'spacy_JJSs_count': 0, 'spacy_count_of_is_big2c_agen_from_big2': 1, 'spacy_count_of_is_big2a_agen_from_big2': 1, 'spacy_count_of_is_big2a_comm_from_big2': 0, 'spacy_count_of_is_big2b_agen_from_big2': 1, 'spacy_count_of_is_big2b_comm_from_big2': 0, 'spacy_count_of_is_nico_full_ability_posit_from_nico': 1, 'spacy_count_of_is_nico_full_status_negat_from_nico': 1, 'spacy_count_of_is_nico_seed_ability_negat_from_nico': 0, 'spacy_count_of_is_nico_full_agency_posit_from_nico': 0, 'spacy_count_of_is_nico_seed_agency_posit_from_nico': 0, 'spacy_count_of_is_nico_seed_agency_negat_from_nico': 0, 'spacy_count_of_is_nico_full_ability_negat_from_nico': 0, 'spacy_count_of_is_nico_seed_ability_posit_from_nico': 0, 'spacy_count_of_is_nico_full_agency_negat_from_nico': 0, 'spacy_count_of_is_nico_full_status_posit_from_nico': 2, 'spacy_count_of_is_nico_seed_status_negat_from_nico': 0, 'spacy_count_of_is_nico_seed_status_posit_from_nico': 0}.
#+end_example

** prod: Convert to dataframe
#+begin_src jupyter-python :async yes
df1 = pd.DataFrame.from_dict(out_dict, orient="index")
# disp_df(df1)
del out_dict
log0.info("DONE")
log0.info(f"{df1.shape = }")
disp_df(df1.head(n=8).sort_index())
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
I: DONE
I: df1.shape = (216, 30)
#+end_example
#+begin_example
   spacy_index0  spacy_word_count                                  spacy_sents  spacy_WORD_count  spacy_NOUN_count  spacy_ADJ_count  spacy_VERB_count  spacy_VERB_count_without_be_and_have  spacy_VB_count  spacy_VB_count_without_be_and_have  spacy_JJ_count  spacy_JJRs_count  spacy_JJSs_count  spacy_count_of_is_big2c_agen_from_big2  spacy_count_of_is_big2a_agen_from_big2  spacy_count_of_is_big2a_comm_from_big2  spacy_count_of_is_big2b_agen_from_big2  spacy_count_of_is_big2b_comm_from_big2  spacy_count_of_is_nico_full_ability_posit_from_nico  spacy_count_of_is_nico_full_status_negat_from_nico  spacy_count_of_is_nico_seed_ability_negat_from_nico  spacy_count_of_is_nico_full_agency_posit_from_nico  spacy_count_of_is_nico_seed_agency_posit_from_nico  spacy_count_of_is_nico_seed_agency_negat_from_nico  spacy_count_of_is_nico_full_ability_negat_from_nico  spacy_count_of_is_nico_seed_ability_posit_from_nico  spacy_count_of_is_nico_full_agency_negat_from_nico  spacy_count_of_is_nico_full_status_posit_from_nico  spacy_count_of_is_nico_seed_status_negat_from_nico  spacy_count_of_is_nico_seed_status_posit_from_nico
0             0                 5             [Cloud that disappears at night]                 5                 1                0                 1                                     1               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
1             1                10  [Cloud that disappears at night and has ...                10                 2                0                 3                                     2               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
2             2                16  [Cloud that disappears at night and has ...                16                 4                0                 5                                     4               0                                   0               0                 0                 0                                       0                                       0                                       1                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
3             3                 8  [Lamp that likes to listen to vacuum cle...                 8                 3                0                 2                                     2               1                                   1               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
4             4                18  [Lamp that likes to listen to vacuum cle...                18                 5                2                 3                                     3               1                                   1               2                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
5             5                29  [Lamp that likes to listen to vacuum cle...                29                 7                2                 5                                     5               2                                   2               2                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    1                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
6             6                 7            [Stone that believes it is a hat]                 7                 2                0                 1                                     1               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
7             7                11  [Stone that believes it is a hat and ble...                11                 2                0                 3                                     3               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
#+end_example
:END:
** prod: Merge source and spacified DataFrames
#+begin_src jupyter-python :async yes
df2 = df0.copy()
df2 = df2.join(df1, lsuffix="__OLD", rsuffix="")
log0.info("DONE: merge")
log0.info(f"{df2.shape = }")
disp_df(df2.head(n=8).sort_index())
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
I: DONE: merge
I: df2.shape = (216, 40)
#+end_example
#+begin_example
   id0                                         text    useful  imageable  thought_provoking   unusual  intentional_agency  strategic_knowledge  acts_in_the_world  motivates_rituals  spacy_index0  spacy_word_count                                  spacy_sents  spacy_WORD_count  spacy_NOUN_count  spacy_ADJ_count  spacy_VERB_count  spacy_VERB_count_without_be_and_have  spacy_VB_count  spacy_VB_count_without_be_and_have  spacy_JJ_count  spacy_JJRs_count  spacy_JJSs_count  spacy_count_of_is_big2c_agen_from_big2  spacy_count_of_is_big2a_agen_from_big2  spacy_count_of_is_big2a_comm_from_big2  spacy_count_of_is_big2b_agen_from_big2  spacy_count_of_is_big2b_comm_from_big2  spacy_count_of_is_nico_full_ability_posit_from_nico  spacy_count_of_is_nico_full_status_negat_from_nico  spacy_count_of_is_nico_seed_ability_negat_from_nico  spacy_count_of_is_nico_full_agency_posit_from_nico  spacy_count_of_is_nico_seed_agency_posit_from_nico  spacy_count_of_is_nico_seed_agency_negat_from_nico  spacy_count_of_is_nico_full_ability_negat_from_nico  spacy_count_of_is_nico_seed_ability_posit_from_nico  spacy_count_of_is_nico_full_agency_negat_from_nico  spacy_count_of_is_nico_full_status_posit_from_nico  spacy_count_of_is_nico_seed_status_negat_from_nico  spacy_count_of_is_nico_seed_status_posit_from_nico
0    1               Cloud that disappears at night  1.684211   3.631579           2.421053  1.894737            1.000000             1.000000           2.142857           1.142857             0                 5             [Cloud that disappears at night]                 5                 1                0                 1                                     1               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
1    2  Cloud that disappears at night and has a...  1.722222   2.666667           3.333333  4.777778            2.538462             2.000000           3.307692           2.307692             1                10  [Cloud that disappears at night and has ...                10                 2                0                 3                                     2               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
2    3  Cloud that disappears at night and has a...  1.473684   2.263158           3.421053  4.684211            3.571429             3.357143           3.571429           3.142857             2                16  [Cloud that disappears at night and has ...                16                 4                0                 5                                     4               0                                   0               0                 0                 0                                       0                                       0                                       1                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
3    4  Lamp that likes to listen to vacuum clea...  1.565217   2.652174           2.826087  4.391304            2.000000             1.714286           1.500000           1.642857             3                 8  [Lamp that likes to listen to vacuum cle...                 8                 3                0                 2                                     2               1                                   1               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
4    5  Lamp that likes to listen to vacuum clea...  2.050000   2.600000           3.350000  4.450000            2.692308             2.076923           3.076923           2.846154             4                18  [Lamp that likes to listen to vacuum cle...                18                 5                2                 3                                     3               1                                   1               2                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
5    6  Lamp that likes to listen to vacuum clea...  2.136364   2.954545           3.590909  4.545455            2.818182             2.363636           3.636364           2.818182             5                29  [Lamp that likes to listen to vacuum cle...                29                 7                2                 5                                     5               2                                   2               2                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    1                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
6    7              Stone that believes it is a hat  1.263158   2.421053           3.421053  4.684211            2.600000             2.600000           2.000000           2.200000             6                 7            [Stone that believes it is a hat]                 7                 2                0                 1                                     1               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
7    8  Stone that believes it is a hat and blee...  1.200000   2.500000           3.350000  4.400000            2.785714             2.428571           2.571429           1.571429             7                11  [Stone that believes it is a hat and ble...                11                 2                0                 3                                     3               0                                   0               0                 0                 0                                       0                                       0                                       0                                       0                                       0                                            0                                                    0                                                   0                                                    0                                                   0                                                   0                                                   0                                                    0                                                    0                                                   0                                                   0                                                   0
#+end_example
:END:
** prod: Drop OLD cols
#+begin_src jupyter-python :async yes
log0.info(f"{df2.shape}")
df2 = df2[df2.columns.drop(list(df2.filter(regex="spacy.*__OLD$")))]
log0.info(f"{df2.shape}")
for col0 in df2.columns:
    print(f"    \"{col0}\",")

#+end_src

#+RESULTS:
#+begin_example
I: (216, 40)
I: (216, 40)
    "id0",
    "text",
    "useful",
    "imageable",
    "thought_provoking",
    "unusual",
    "intentional_agency",
    "strategic_knowledge",
    "acts_in_the_world",
    "motivates_rituals",
    "spacy_index0",
    "spacy_word_count",
    "spacy_sents",
    "spacy_WORD_count",
    "spacy_NOUN_count",
    "spacy_ADJ_count",
    "spacy_VERB_count",
    "spacy_VERB_count_without_be_and_have",
    "spacy_VB_count",
    "spacy_VB_count_without_be_and_have",
    "spacy_JJ_count",
    "spacy_JJRs_count",
    "spacy_JJSs_count",
    "spacy_count_of_is_big2c_agen_from_big2",
    "spacy_count_of_is_big2a_agen_from_big2",
    "spacy_count_of_is_big2a_comm_from_big2",
    "spacy_count_of_is_big2b_agen_from_big2",
    "spacy_count_of_is_big2b_comm_from_big2",
    "spacy_count_of_is_nico_full_ability_posit_from_nico",
    "spacy_count_of_is_nico_full_status_negat_from_nico",
    "spacy_count_of_is_nico_seed_ability_negat_from_nico",
    "spacy_count_of_is_nico_full_agency_posit_from_nico",
    "spacy_count_of_is_nico_seed_agency_posit_from_nico",
    "spacy_count_of_is_nico_seed_agency_negat_from_nico",
    "spacy_count_of_is_nico_full_ability_negat_from_nico",
    "spacy_count_of_is_nico_seed_ability_posit_from_nico",
    "spacy_count_of_is_nico_full_agency_negat_from_nico",
    "spacy_count_of_is_nico_full_status_posit_from_nico",
    "spacy_count_of_is_nico_seed_status_negat_from_nico",
    "spacy_count_of_is_nico_seed_status_posit_from_nico",
#+end_example

** prod: Convert categorical data types to objects (important for Datasets)
#+begin_src jupyter-python :async yes
# df2[df2.select_dtypes(["category"]).columns] = df2.select_dtypes(["category"]).apply(lambda x: x.astype("object"))
df2[df2.select_dtypes(["category"]).columns] = df2.select_dtypes(["category"]).apply(lambda x: x.astype(str))
log0.info("DONE (categ to str)")
disp_df(df2.dtypes, max_rows=500)
#+end_src

#+RESULTS:
:RESULTS:
: I: DONE (categ to str)
#+begin_example
id0                                                      int64
text                                                    object
useful                                                 float64
imageable                                              float64
thought_provoking                                      float64
unusual                                                float64
intentional_agency                                     float64
strategic_knowledge                                    float64
acts_in_the_world                                      float64
motivates_rituals                                      float64
spacy_index0                                             int64
spacy_word_count                                         int64
spacy_sents                                             object
spacy_WORD_count                                         int64
spacy_NOUN_count                                         int64
spacy_ADJ_count                                          int64
spacy_VERB_count                                         int64
spacy_VERB_count_without_be_and_have                     int64
spacy_VB_count                                           int64
spacy_VB_count_without_be_and_have                       int64
spacy_JJ_count                                           int64
spacy_JJRs_count                                         int64
spacy_JJSs_count                                         int64
spacy_count_of_is_big2c_agen_from_big2                   int64
spacy_count_of_is_big2a_agen_from_big2                   int64
spacy_count_of_is_big2a_comm_from_big2                   int64
spacy_count_of_is_big2b_agen_from_big2                   int64
spacy_count_of_is_big2b_comm_from_big2                   int64
spacy_count_of_is_nico_full_ability_posit_from_nico      int64
spacy_count_of_is_nico_full_status_negat_from_nico       int64
spacy_count_of_is_nico_seed_ability_negat_from_nico      int64
spacy_count_of_is_nico_full_agency_posit_from_nico       int64
spacy_count_of_is_nico_seed_agency_posit_from_nico       int64
spacy_count_of_is_nico_seed_agency_negat_from_nico       int64
spacy_count_of_is_nico_full_ability_negat_from_nico      int64
spacy_count_of_is_nico_seed_ability_posit_from_nico      int64
spacy_count_of_is_nico_full_agency_negat_from_nico       int64
spacy_count_of_is_nico_full_status_posit_from_nico       int64
spacy_count_of_is_nico_seed_status_negat_from_nico       int64
spacy_count_of_is_nico_seed_status_posit_from_nico       int64
dtype: object
#+end_example
:END:

** prod: Get means
#+begin_src jupyter-python :async yes
maybe_drop = False
maybe_drop = True

count_cols = [
    col0 for col0 in df2.columns if
    (col0.startswith("spacy_")) and \
    ("count" in col0) and \
    (col0!="spacy_WORD_count") and \
    ("_as_dict" not in col0) and
    ("votes_count" not in col0)
]
for col0 in count_cols:
    log0.info(f"{col0 = }")
    col1 = col0.replace("count", "mean")
    df2[col1] = df2[col0]/df2["spacy_WORD_count"]
    if maybe_drop:
        df2.drop(columns=[col0], inplace=True)

disp_cols = ["WORD_count", "spacy_mean_of_is_big2c_agen_from_big2", "spacy_mean_of_is_nico_full_status_posit_from_nico"]
disp_df(df2.sample(n=5).sort_index(), width=4400)
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
I: col0 = 'spacy_word_count'
I: col0 = 'spacy_NOUN_count'
I: col0 = 'spacy_ADJ_count'
I: col0 = 'spacy_VERB_count'
I: col0 = 'spacy_VERB_count_without_be_and_have'
I: col0 = 'spacy_VB_count'
I: col0 = 'spacy_VB_count_without_be_and_have'
I: col0 = 'spacy_JJ_count'
I: col0 = 'spacy_JJRs_count'
I: col0 = 'spacy_JJSs_count'
I: col0 = 'spacy_count_of_is_big2c_agen_from_big2'
I: col0 = 'spacy_count_of_is_big2a_agen_from_big2'
I: col0 = 'spacy_count_of_is_big2a_comm_from_big2'
I: col0 = 'spacy_count_of_is_big2b_agen_from_big2'
I: col0 = 'spacy_count_of_is_big2b_comm_from_big2'
I: col0 = 'spacy_count_of_is_nico_full_ability_posit_from_nico'
I: col0 = 'spacy_count_of_is_nico_full_status_negat_from_nico'
I: col0 = 'spacy_count_of_is_nico_seed_ability_negat_from_nico'
I: col0 = 'spacy_count_of_is_nico_full_agency_posit_from_nico'
I: col0 = 'spacy_count_of_is_nico_seed_agency_posit_from_nico'
I: col0 = 'spacy_count_of_is_nico_seed_agency_negat_from_nico'
I: col0 = 'spacy_count_of_is_nico_full_ability_negat_from_nico'
I: col0 = 'spacy_count_of_is_nico_seed_ability_posit_from_nico'
I: col0 = 'spacy_count_of_is_nico_full_agency_negat_from_nico'
I: col0 = 'spacy_count_of_is_nico_full_status_posit_from_nico'
I: col0 = 'spacy_count_of_is_nico_seed_status_negat_from_nico'
I: col0 = 'spacy_count_of_is_nico_seed_status_posit_from_nico'
#+end_example
#+begin_example
     id0                                         text    useful  imageable  thought_provoking   unusual  intentional_agency  strategic_knowledge  acts_in_the_world  motivates_rituals  spacy_index0                                  spacy_sents  spacy_WORD_count  spacy_word_mean  spacy_NOUN_mean  spacy_ADJ_mean  spacy_VERB_mean  spacy_VERB_mean_without_be_and_have  spacy_VB_mean  spacy_VB_mean_without_be_and_have  spacy_JJ_mean  spacy_JJRs_mean  spacy_JJSs_mean  spacy_mean_of_is_big2c_agen_from_big2  spacy_mean_of_is_big2a_agen_from_big2  spacy_mean_of_is_big2a_comm_from_big2  spacy_mean_of_is_big2b_agen_from_big2  spacy_mean_of_is_big2b_comm_from_big2  spacy_mean_of_is_nico_full_ability_posit_from_nico  spacy_mean_of_is_nico_full_status_negat_from_nico  spacy_mean_of_is_nico_seed_ability_negat_from_nico  spacy_mean_of_is_nico_full_agency_posit_from_nico  spacy_mean_of_is_nico_seed_agency_posit_from_nico  spacy_mean_of_is_nico_seed_agency_negat_from_nico  spacy_mean_of_is_nico_full_ability_negat_from_nico  spacy_mean_of_is_nico_seed_ability_posit_from_nico  spacy_mean_of_is_nico_full_agency_negat_from_nico  spacy_mean_of_is_nico_full_status_posit_from_nico  spacy_mean_of_is_nico_seed_status_negat_from_nico  spacy_mean_of_is_nico_seed_status_posit_from_nico
18    19  Cloud that is so big it can be seen acro...  1.500000   2.833333           3.222222  4.111111            1.750000             1.250000           4.166667           2.083333            18  [Cloud that is so big it can be seen acr...                12              1.0         0.083333        0.083333         0.083333                             0.083333       0.083333                           0.000000       0.083333              0.0              0.0                               0.000000                               0.000000                               0.000000                               0.000000                               0.000000                                     0.083333                                            0.000000                                                0.0                                                 0.0                                                0.0                                                0.0                                                0.0                                              0.0000                                                 0.0                                           0.083333                                                0.0                                                0.0
71    72  Child that has lived four times in histo...  2.736842   2.421053           3.894737  4.631579            4.750000             4.166667           4.333333           3.916667            71  [Child that has lived four times in hist...                25              1.0         0.240000        0.080000         0.160000                             0.120000       0.040000                           0.040000       0.080000              0.0              0.0                               0.000000                               0.000000                               0.000000                               0.000000                               0.000000                                     0.000000                                            0.000000                                                0.0                                                 0.0                                                0.0                                                0.0                                                0.0                                              0.0000                                                 0.0                                           0.000000                                                0.0                                                0.0
112  113  Lamp that loves listening to gossip and ...  1.764706   3.058824           2.823529  4.764706            3.700000             3.300000           3.700000           2.900000           112  [Lamp that loves listening to gossip and...                11              1.0         0.272727        0.000000         0.363636                             0.363636       0.090909                           0.090909       0.000000              0.0              0.0                               0.090909                               0.090909                               0.090909                               0.000000                               0.090909                                     0.000000                                            0.000000                                                0.0                                                 0.0                                                0.0                                                0.0                                                0.0                                              0.0000                                                 0.0                                           0.000000                                                0.0                                                0.0
122  123  Rabbit that is an advanced robot and has...  1.700000   2.650000           3.350000  4.550000            4.083333             4.416667           4.583333           3.500000           122  [Rabbit that is an advanced robot and ha...                23              1.0         0.260870        0.130435         0.173913                             0.130435       0.043478                           0.043478       0.130435              0.0              0.0                               0.000000                               0.000000                               0.043478                               0.043478                               0.043478                                     0.086957                                            0.086957                                                0.0                                                 0.0                                                0.0                                                0.0                                                0.0                                              0.0000                                                 0.0                                           0.000000                                                0.0                                                0.0
130  131  Lamp that is so bright it causes blindne...  2.304348   2.913043           3.217391  3.956522            1.307692             1.307692           3.538462           2.153846           130  [Lamp that is so bright it causes blindn...                16              1.0         0.125000        0.062500         0.187500                             0.187500       0.000000                           0.000000       0.062500              0.0              0.0                               0.000000                               0.000000                               0.000000                               0.000000                               0.000000                                     0.125000                                            0.000000                                                0.0                                                 0.0                                                0.0                                                0.0                                                0.0                                              0.0625                                                 0.0                                           0.000000                                                0.0                                                0.0
#+end_example
:END:
** prod: Copy
#+begin_src jupyter-python :async yes
df8 = df2.copy()

#+end_src

#+RESULTS:

** prod: Checkup columns
#+begin_src jupyter-python :async yes
log0.info(f"{df8.shape}")
for col0 in df8.columns:
    print(f"    \"{col0}\",")

#+end_src

#+RESULTS:
#+begin_example
I: (216, 40)
    "id0",
    "text",
    "useful",
    "imageable",
    "thought_provoking",
    "unusual",
    "intentional_agency",
    "strategic_knowledge",
    "acts_in_the_world",
    "motivates_rituals",
    "spacy_index0",
    "spacy_sents",
    "spacy_WORD_count",
    "spacy_word_mean",
    "spacy_NOUN_mean",
    "spacy_ADJ_mean",
    "spacy_VERB_mean",
    "spacy_VERB_mean_without_be_and_have",
    "spacy_VB_mean",
    "spacy_VB_mean_without_be_and_have",
    "spacy_JJ_mean",
    "spacy_JJRs_mean",
    "spacy_JJSs_mean",
    "spacy_mean_of_is_big2c_agen_from_big2",
    "spacy_mean_of_is_big2a_agen_from_big2",
    "spacy_mean_of_is_big2a_comm_from_big2",
    "spacy_mean_of_is_big2b_agen_from_big2",
    "spacy_mean_of_is_big2b_comm_from_big2",
    "spacy_mean_of_is_nico_full_ability_posit_from_nico",
    "spacy_mean_of_is_nico_full_status_negat_from_nico",
    "spacy_mean_of_is_nico_seed_ability_negat_from_nico",
    "spacy_mean_of_is_nico_full_agency_posit_from_nico",
    "spacy_mean_of_is_nico_seed_agency_posit_from_nico",
    "spacy_mean_of_is_nico_seed_agency_negat_from_nico",
    "spacy_mean_of_is_nico_full_ability_negat_from_nico",
    "spacy_mean_of_is_nico_seed_ability_posit_from_nico",
    "spacy_mean_of_is_nico_full_agency_negat_from_nico",
    "spacy_mean_of_is_nico_full_status_posit_from_nico",
    "spacy_mean_of_is_nico_seed_status_negat_from_nico",
    "spacy_mean_of_is_nico_seed_status_posit_from_nico",
#+end_example

** Cleanup
#+begin_src jupyter-python :async yes
cols9 = {
    "useful": "useful",
    "imageable": "imageable",
    "thought_provoking": "thought_provoking",
    "unusual": "unusual",
    "intentional_agency": "intentional_agency",
    "strategic_knowledge": "strategic_knowledge",
    "acts_in_the_world": "acts_in_the_world",
    "motivates_rituals": "motivates_rituals",
    "spacy_mean_of_is_big2a_agen_from_big2": "PietA",
    "spacy_mean_of_is_big2b_agen_from_big2": "PietB",
    "spacy_mean_of_is_big2c_agen_from_big2": "PietC",
    "spacy_mean_of_is_nico_full_agency_posit_from_nico": "NicoPos",
    "spacy_mean_of_is_nico_full_agency_negat_from_nico": "NicoNeg",
    # "spacy_mean_of_is_nico_full_ability_posit_from_nico": "",
    # "spacy_mean_of_is_nico_full_ability_negat_from_nico": "",
    # "spacy_mean_of_is_nico_full_status_negat_from_nico": "",
    # "spacy_mean_of_is_nico_full_status_posit_from_nico": "",
    "spacy_sents": "sents",
    "text": "text",
}
df9 = df8[cols9.keys()].copy()
df9.rename(columns=cols9, inplace=True, errors="ignore")

log0.info(f"{df9.shape = }")
disp_df(df9.sample(n=8).sort_index())
#+end_src

#+RESULTS:
:RESULTS:
: I: df9.shape = (216, 15)
#+begin_example
       useful  imageable  thought_provoking   unusual  intentional_agency  strategic_knowledge  acts_in_the_world  motivates_rituals  PietA     PietB  PietC   NicoPos  NicoNeg                                        sents                                         text
19   1.578947   3.000000           3.473684  4.473684            1.882353             1.588235           3.176471           1.941176    0.0  0.052632    0.0  0.000000      0.0  [Cloud that is so big it can be seen acr...  Cloud that is so big it can be seen acro...
39   3.304348   4.391304           1.434783  1.478261            1.142857             1.142857           2.428571           2.785714    0.0  0.000000    0.0  0.000000      0.0                          [Lamp that is tall]                            Lamp that is tall
51   2.437500   4.000000           1.812500  1.500000            4.571429             4.642857           3.571429           3.428571    0.0  0.000000    0.0  0.000000      0.0          [Person who enjoys classical music]            Person who enjoys classical music
84   2.238095   3.809524           2.666667  2.142857            3.727273             2.818182           3.181818           2.000000    0.0  0.000000    0.0  0.000000      0.0  [Bird that survived being shot in the wing]    Bird that survived being shot in the wing
98   1.842105   3.473684           2.000000  2.263158            1.214286             1.214286           2.785714           1.500000    0.0  0.000000    0.0  0.047619      0.0  [Icicle that is about as long as a ruler...  Icicle that is about as long as a ruler ...
145  1.500000   4.454545           1.863636  1.863636            1.583333             1.333333           3.416667           1.583333    0.0  0.000000    0.0  0.000000      0.0     [Cloud that is hailing and is dark grey]       Cloud that is hailing and is dark grey
150  2.277778   4.444444           2.055556  2.166667            1.000000             1.125000           1.625000           2.187500    0.0  0.000000    0.0  0.000000      0.0  [Stone that is roughly triangular in shape]    Stone that is roughly triangular in shape
151  3.238095   4.238095           2.190476  1.857143            1.307692             1.307692           2.000000           2.230769    0.0  0.000000    0.0  0.000000      0.0  [Stone that is roughly triangular in sha...  Stone that is roughly triangular in shap...
#+end_example
:END:
** Insert NicoCom
#+begin_src jupyter-python :async yes
df9.insert(13, "NicoCom", df9.NicoPos-df9.NicoNeg)

log0.info(f"{df9.shape = }")
disp_df(df9.sample(n=8).sort_index())
#+end_src

#+RESULTS:
:RESULTS:
: I: df9.shape = (216, 16)
#+begin_example
       useful  imageable  thought_provoking   unusual  intentional_agency  strategic_knowledge  acts_in_the_world  motivates_rituals  PietA  PietB  PietC  NicoPos  NicoNeg  NicoCom                                        sents                                         text
32   1.263158   3.000000           3.000000  4.421053            3.250000             2.437500           2.937500           2.125000    0.0    0.0    0.0      0.0      0.0      0.0  [Rabbit wearing a tie-dyed robe and has ...  Rabbit wearing a tie-dyed robe and has s...
34   1.619048   2.714286           2.809524  4.333333            4.375000             4.312500           4.625000           3.187500    0.0    0.0    0.0      0.0      0.0      0.0  [Person who hops everywhere they go and ...  Person who hops everywhere they go and w...
46   2.863636   4.272727           2.363636  1.727273            2.133333             2.066667           2.666667           2.733333    0.0    0.0    0.0      0.0      0.0      0.0  [Tree that has moss growing on its trunk...  Tree that has moss growing on its trunk ...
57   2.052632   2.736842           3.000000  3.947368            2.600000             1.933333           2.533333           2.133333    0.0    0.0    0.0      0.0      0.0      0.0           [Rocking chair that prays to Zeus]             Rocking chair that prays to Zeus
65   1.809524   2.666667           3.380952  4.000000            2.818182             2.545455           2.636364           2.818182    0.0    0.0    0.0      0.0      0.0      0.0  [Cactus that likes to be eaten and is as...  Cactus that likes to be eaten and is as ...
79   1.333333   3.722222           3.000000  4.222222            1.272727             1.181818           1.727273           1.636364    0.0    0.0    0.0      0.0      0.0      0.0  [Icicle that has been spray painted gree...  Icicle that has been spray painted green...
124  4.500000   3.545455           3.863636  4.545455            4.571429             4.500000           4.214286           4.000000    0.0    0.0    0.0      0.0      0.0      0.0  [Person who can turn into animals and ca...  Person who can turn into animals and can...
130  2.304348   2.913043           3.217391  3.956522            1.307692             1.307692           3.538462           2.153846    0.0    0.0    0.0      0.0      0.0      0.0  [Lamp that is so bright it causes blindn...  Lamp that is so bright it causes blindne...
#+end_example
:END:

** Checkup
#+begin_src jupyter-python :async yes
cond = (df9.NicoPos>0) & (df9.NicoNeg>0)
log0.info(f"{df9[cond].shape = }")
disp_df(df9[cond].head(n=8).sort_index())
#+end_src

#+RESULTS:
:RESULTS:
: I: df9[cond].shape = (1, 16)
#+begin_example
     useful  imageable  thought_provoking  unusual  intentional_agency  strategic_knowledge  acts_in_the_world  motivates_rituals  PietA     PietB  PietC   NicoPos   NicoNeg   NicoCom                                        sents                                         text
149     4.2        4.0                2.7      2.0                 1.5                  1.6                3.7                4.1    0.0  0.133333    0.0  0.133333  0.066667  0.066667  [Lamp that is bright and can be dimmed a...  Lamp that is bright and can be dimmed an...
#+end_example
:END:

OLD
#+RESULTS:
:RESULTS:
: I: df9[cond].shape = (6, 10)
#+begin_example
     idx0    HumEval     PietA     PietB     PietC   NicoPos   NicoNeg   NicoCom                                        sents                                         text
14     14  49.776132  0.033333  0.016667  0.033333  0.016667  0.016667  0.000000  [Healthcare Social Workers, Provide indi...  Healthcare Social Workers, Provide indiv...
15     15  78.902065  0.000000  0.000000  0.000000  0.117647  0.029412  0.088235  [Physical Therapist Aides, Under close s...  Physical Therapist Aides, Under close su...
86     86  52.514268  0.025641  0.025641  0.025641  0.025641  0.025641  0.000000  [Machinists, Set up and operate a variet...  Machinists, Set up and operate a variety...
88     88  53.010654  0.000000  0.000000  0.000000  0.040000  0.040000  0.000000  [Ambulance Drivers and Attendants, Excep...  Ambulance Drivers and Attendants, Except...
90     90  62.243797  0.016949  0.000000  0.016949  0.033898  0.016949  0.016949  [Marriage and Family Therapists, Diagnos...  Marriage and Family Therapists, Diagnose...
117   117  70.421701  0.000000  0.027027  0.000000  0.027027  0.027027  0.000000  [Pharmacists, Dispense drugs prescribed ...  Pharmacists, Dispense drugs prescribed b...
#+end_example
:END:

** Save
#+begin_src jupyter-python :async yes
import pathlib
import csv
import datetime as dt
from pytz import timezone as tz
tz0 = tz("Europe/Berlin")

dir0 = "../../data/v0003_supernatural/u1004_nlp/"
dir0 = pathlib.Path(dir0)
dir0.mkdir(mode=0o700, parents=True, exist_ok=True)
assert dir0.exists(), f"The data directory dir0={str(dir0)} was not found!"

now0 = [dt.datetime.now(tz0).strftime("%Y%m%dT%H%M%S")]
now0 = []
pfx0 = ["supernatural"]
sfx0 = ["nlp"]

bfn0 = dir0/"_".join(pfx0+now0+sfx0).replace(".", "_")

xtn0 = ".pkl"
ofn0 = bfn0.with_suffix(xtn0)
log0.info(f"saving: {ofn0}...")
df9.to_pickle(ofn0)

xtn0 = ".csv"
ofn0 = bfn0.with_suffix(xtn0)
log0.info(f"saving: {ofn0}...")
df9.to_csv(ofn0, index=False, quoting=csv.QUOTE_NONNUMERIC)

xtn0 = ".xlsx"
ofn0 = bfn0.with_suffix(xtn0)
log0.info(f"saving: {ofn0}...")
df9.to_excel(ofn0)

xtn0 = ".jsonl"
ofn0 = bfn0.with_suffix(xtn0)
log0.info(f"saving: {ofn0}...")
with open(ofn0, "w") as fh: pass
srsly.write_jsonl(ofn0, df9.to_dict(orient="records"))

log0.info("DONE")

#+end_src

#+RESULTS:
#+begin_example
I: saving: ../../data/v0003_supernatural/u1004_nlp/supernatural_nlp.pkl...
I: saving: ../../data/v0003_supernatural/u1004_nlp/supernatural_nlp.csv...
I: saving: ../../data/v0003_supernatural/u1004_nlp/supernatural_nlp.xlsx...
I: saving: ../../data/v0003_supernatural/u1004_nlp/supernatural_nlp.jsonl...
I: DONE
#+end_example
