% Created 2023-06-01 Thu 12:16
% Intended LaTeX compiler: xelatex
\documentclass[a4paper,10pt,onecolumn,oneside,openright]{article}
\usepackage[no-math]{fontspec}
\newfontfamily\cyrillicfont{CMU Serif}
\newfontfamily\cyrillicfontsf[Script=Cyrillic]{Linux Libertine O}
\newfontfamily\cyrillicfonttt[Script=Cyrillic]{Hack}
\setmainfont[
  Ligatures=TeX,
  Extension=.otf,
  BoldFont=cmunbx,
  ItalicFont=cmunti,
  BoldItalicFont=cmunbi,
]{cmunrm}
\usepackage[Latin,Cyrillics]{ucharclasses}
\setTransitionsForCyrillics{\begingroup\cyrillicfont}{\endgroup}
\usepackage{polyglossia}
\setdefaultlanguage[variant=british]{english}
\setotherlanguage{latin}
\setotherlanguage{greek}
\setotherlanguage{russian}
\setotherlanguage{polish}
\setotherlanguage{german}
\setotherlanguage{ukrainian}
\newcommand{\RU}[1]{\foreignlanguage{russian}{#1}}
\usepackage{url}
\usepackage{listings}
\usepackage{array}
\usepackage{tabularx}
\newenvironment{conditions}
  {\par\vspace{\abovedisplayskip}\noindent
   \begin{tabular}{>{$}l<{$} @{} >{${}}c<{{}$} @{} l}}
  {\end{tabular}\par\vspace{\belowdisplayskip}}
\newenvironment{conditions*}
  {\par\vspace{\abovedisplayskip}\noindent
   \tabularx{\columnwidth}{>{$}l<{$} @{}>{${}}c<{{}$}@{} >{\raggedright\arraybackslash}X}}
  {\endtabularx\par\vspace{\belowdisplayskip}}
\usepackage[tableposition=t]{caption}
\captionsetup[table]{skip=8pt}
\usepackage{pdflscape}
\usepackage{adjustbox}
\usepackage[tableposition=t]{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsfonts}
\usepackage{soul}
\usepackage{xunicode}
\usepackage[normalem]{ulem}
\usepackage{fixltx2e}
\usepackage[unicode]{hyperref}
\usepackage{cleveref}
\newcommand*{\fullref}[1]{\hyperref[{#1}]{\ref*{#1} \nameref*{#1}}}
\newcommand*{\fullRef}[1]{\nameCref{#1} \hyperref[{#1}]{\ref*{#1} \nameref*{#1}}}
\newcommand*{\fullREF}[1]{\nameCref{#1} \ref{#1}: \nameref*{#1}}
\newcommand*{\FullREF}[1]{\nameCref{#1} \ref{#1} (\nameref*{#1})}
\newcommand*{\eqnCref}[1]{\nameCref{#1} \ref{#1}}
\newcommand*{\EqnCref}[1]{\nameCref{#1} \ref*{#1}}
\newcommand{\citinf}{{\newline\hspace*{\fill}}\textasteriskcentered}
\newcommand{\citfix}{{\hspace*{\fill}}\textasteriskcentered}
\newcommand{\citsrc}{{\vadjust{\vspace{8pt}}\nolinebreak\hspace{\fill}\mbox{}\linebreak\hspace*{\fill}\textemdash\space}}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{nicefrac}
\usepackage{amscd}
\usepackage{amstext}
\usepackage{threeparttable}
\AtBeginDocument{\hypersetup{pdfauthor={Jan Nikadon},pdftitle={\thetitle},pdfsubject={subject},pdfkeywords={keyword1,}{keyword2},}}
\hypersetup{xetex,colorlinks=true,linktocpage=true,linkcolor=RoyalPurple,citecolor=RoyalPurple,filecolor=RoyalBlue,urlcolor=RoyalBlue,pagebackref=true,plainpages=false,pdfpagelabels=true,bookmarksnumbered=true,}
\PassOptionsToPackage{dateabbrev=false,natbib=true,style=apa,backref=true,backrefstyle=two,dashed=false,hyperref=true,backend=biber,maxbibnames=99,firstinits=true,giveninits=false,uniquename=init,citetracker=true,parentracker=true,url=false,doi=true,}{biblatex}
\usepackage{biblatex}
\usepackage[newfloat]{minted}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\restylefloat{table}
\usepackage{titling}
\usepackage[usenames,dvipsnames,svgnames]{xcolor}
\definecolor{fuchsiapink}{rgb}{1.0, 0.47, 1.0}
\definecolor{cream}{rgb}{1.00, 0.99, 0.82}
\definecolor{champagne}{rgb}{0.97, 0.91, 0.81}
\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}
\definecolor{blanchedalmond}{rgb}{1.0, 0.92, 0.8}
\definecolor{brilliantlavender}{rgb}{0.96, 0.73, 1.0}
\IfFileExists{~/bib_cat/ref.bib}{\addbibresource{~/bib_cat/ref.bib}}{}
\IfFileExists{main.bib}{\addbibresource{main.bib}}{}
\date{}
\title{S7101\_compare\_models}
\begin{document}

\maketitle

\section{Boilerplate}
\label{sec:orge4dde1e}
\section{Imports}
\label{sec:org0d0a45b}
\subsection{prod: NVM}
\label{sec:org2afca86}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
from nvm import disp_df
from nvm import repr_df
from nvm import rdf
from nvm import ddf
from nvm import clean_str
from nvm.aux_str import CLEAN_STR_MAPPINGS_LARGE as maps0
from nvm.aux_str import REGEX_ABC_DASH_XYZ_ASTERISK as re0
from nvm.aux_pandas import fix_column_names
\end{minted}

\subsection{prod: Basics}
\label{sec:org3658a79}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
import os
import pathlib
import numpy as np
import pandas as pd
import re
import json
import yaml
import srsly
import uuid
import random
import numbers
from collections import OrderedDict
from contextlib import ExitStack
import warnings
# warnings.warn("\nwarning")
from hashlib import md5
import humanfriendly as hf
import time
import datetime as dt
from pytz import timezone as tz
tz0 = tz("Europe/Berlin")
from glob import glob
from tqdm import tqdm
import logging
log0.info("DONE: basic imports")
\end{minted}

\begin{verbatim}
I: DONE: basic imports
\end{verbatim}

\subsection{prod: Extra imports and settings}
\label{sec:org6cff76a}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
from contexttimer import Timer
import textwrap

HOME = pathlib.Path.home()

tqdm.pandas()

import matplotlib
from matplotlib import pyplot as plt
# import seaborn as sns
# import plotly.graph_objects as go
# import plotly.express as px

# get_ipython().run_line_magic("matplotlib", "qt")
# get_ipython().run_line_magic("matplotlib", "inline")

with Timer() as elapsed:
    time.sleep(0.001)

log0.info(hf.format_timespan(elapsed.elapsed))

log0.info("DONE: extra imports and settings")
\end{minted}

\begin{verbatim}
I: 0 seconds
I: DONE: extra imports and settings
\end{verbatim}

\section{Extra Imports}
\label{sec:orgea96c46}
\subsection{prod: More extra imports and settings}
\label{sec:org4509f2a}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}

log0.info("DONE: more extra imports and settings")
\end{minted}

\begin{verbatim}
I: DONE: more extra imports and settings
\end{verbatim}

\section{Notes}
\label{sec:org1762a86}
\section{Process}
\label{sec:org806ea01}
\subsection{prod: Load data}
\label{sec:org086b9bd}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
dir0 = "../../data/d0088_trained_models/"
dir0 = pathlib.Path(dir0)
# dir0.mkdir(mode=0o700, parents=True, exist_ok=True)
assert dir0.exists(), f"The data directory dir0={str(dir0)} not found!"

glob0 = dir0.glob("*/metadata.yaml")
glob0 = sorted(list(glob0))
log0.info(f"{len(glob0)}")

data0 = []
for item0 in glob0:
    data0.append(srsly.read_yaml(item0))

log0.info(f"{len(data0)}")

df0 = pd.DataFrame.from_records(data0)

drop_cols = [
    "data_dir",
    "goldstd",
    "extn",
    "status",
    "testing",
    "init_metrics",
]
df0.drop(columns=drop_cols, inplace=True, errors="ignore")
df0["out_dir"] = df0.out_dir.apply(lambda x: x.split("/")[-1])

log0.info(f"{df0.shape = }")
disp_df(df0)
\end{minted}
\subsection{Check dictionary in columns}
\label{sec:orge4c98aa}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
col0 = "train_metrics"
col2 = "test_metrics"

keys0 = df0[col0][0].keys()
keys2 = df0[col2][0].keys()

keys0 = [item for item in keys0]
keys2 = ["_".join(item.split("_")[1:]) for item in keys2]


print(keys0)
print(keys2)
print(srsly.json_dumps(df0[col0][0], indent=2))
print(srsly.json_dumps(df0[col2][0], indent=2))
\end{minted}
\subsection{Check Series}
\label{sec:org9fb3e72}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
log0.info(f"{df0.shape = }")

col0 = "gold_metrics"
disp_df(df0[col0].apply(pd.Series).add_prefix("GOLD_"))
\end{minted}

\subsection{Check columns}
\label{sec:org4ceb5bc}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
for col0 in df0.columns:
    print(f"    \"{col0}\",")
\end{minted}
\subsection{Data wrangle}
\label{sec:orgf2e3822}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
dict_cols = [
    "train_metrics",
    "eval_metrics",
    "test_metrics",
    "gold_metrics",
]
df2 = df0.copy()
for col0 in dict_cols:
    prefix = col0.split("_")[0] + "_"
    log0.info(f"{prefix}")
    se0 = df2[col0].apply(pd.Series).copy()
    se0 = se0.add_prefix(prefix.upper())
    df2 = pd.concat([df2, se0], axis=1).copy()
    df2.columns = df2.columns.str.replace(prefix.upper()+"test_", prefix.upper())
    df2.columns = df2.columns.str.replace(prefix.upper()+"eval_", prefix.upper())
    df2.drop(columns=[col0], inplace=True, errors="ignore")

df2 = df2.dropna(how="all", axis=1)

df2 = df2.loc[:, ~df2.columns.str.endswith("_runtime")]
df2 = df2.loc[:, ~df2.columns.str.endswith("_samples_per_second")]
df2 = df2.loc[:, ~df2.columns.str.endswith("_steps_per_second")]

df2.sort_values(by=["dataset", "out_dir"], inplace=True)

log0.info(f"{df2.shape = }")
disp_df(df2)
\end{minted}
\subsection{New columns}
\label{sec:orgdeb09b8}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
for col0 in df2.columns:
    print(f"    \"{col0}\",")
\end{minted}

\begin{verbatim}
    "num_epochs",
    "batch_size",
    "random_state",
    "seed",
    "max_length",
    "dataset",
    "model_name",
    "date",
    "out_dir",
    "full_len",
    "train_len",
    "eval_len",
    "test_len",
    "gold_len",
    "finished",
    "TRAIN_loss",
    "TRAIN_rmse",
    "TRAIN_mse",
    "TRAIN_mae",
    "TRAIN_r2",
    "TRAIN_max_err",
    "TRAIN_exp_var",
    "TRAIN_epoch",
    "EVAL_loss",
    "EVAL_rmse",
    "EVAL_mse",
    "EVAL_mae",
    "EVAL_r2",
    "EVAL_max_err",
    "EVAL_exp_var",
    "EVAL_epoch",
    "TEST_loss",
    "TEST_rmse",
    "TEST_mse",
    "TEST_mae",
    "TEST_r2",
    "TEST_max_err",
    "TEST_exp_var",
    "GOLD_loss",
    "GOLD_rmse",
    "GOLD_mse",
    "GOLD_mae",
    "GOLD_r2",
    "GOLD_max_err",
    "GOLD_exp_var",
\end{verbatim}


\subsection{DF4}
\label{sec:orgc040207}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
cols4 = [
    "seed",
    "dataset",
    "model_name",
    "date",
    "num_epochs",
    "batch_size",
    "out_dir",
    "random_state",
    # "full_len",
    # "train_len",
    # "eval_len",
    "test_len",
    "gold_len",
    # "finished",
    # "TRAIN_epoch",
    # "EVAL_epoch",
    # "TRAIN_loss",
    # "EVAL_loss",
    "TEST_loss",
    "GOLD_loss",
    # "TRAIN_rmse",
    # "EVAL_rmse",
    "TEST_rmse",
    "GOLD_rmse",
    # "TRAIN_mse",
    # "EVAL_mse",
    "TEST_mse",
    "GOLD_mse",
    # "TRAIN_mae",
    # "EVAL_mae",
    "TEST_mae",
    "GOLD_mae",
    # "TRAIN_r2",
    # "EVAL_r2",
    "TEST_r2",
    "GOLD_r2",
    # "TRAIN_max_err",
    # "EVAL_max_err",
    "TEST_max_err",
    "GOLD_max_err",
    # "TRAIN_exp_var",
    # "EVAL_exp_var",
    "TEST_exp_var",
    "GOLD_exp_var",
]
df4 = df2[cols4].copy()
log0.info(f"{df4.shape = }")
disp_df(df4)
\end{minted}

\subsection{Check models for removal}
\label{sec:org2fcddea}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
df_keep = df4[df4.batch_size==64]
log0.info(f"{df_keep.shape = }")
disp_df(df_keep.sort_values(by=["date"]))
\end{minted}

\subsection{Check seed values}
\label{sec:orgb013775}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
disp_df(df4[df4.batch_size>=64].seed.value_counts())
# disp_df(df4[df4.batch_size>=64].testing.value_counts())
\end{minted}
\subsection{Filter}
\label{sec:org0e01899}
\begin{minted}[framerule=0.5pt,fontsize=\small,mathescape=,bgcolor=blanchedalmond!80,samepage=,xrightmargin=0.0cm,xleftmargin=0.0cm,linenos=]{python}
cols8 = dict(
    # finished="finished",
    # out_dir="out_dir",
    random_state="random_state",
    seed="seed",
    date="date",
    model_name="Base model",
    dataset="Fine-tuning dataset",
    num_epochs="Number of epochs",
    batch_size="Batch size",
    # full_len="Full fine-tuning",
    train_len="Traininig data",
    eval_len="Evaluation data",
    test_len="Test data",
    gold_len="Gold standard",
    # TRAIN_epoch="TRAIN_epoch",
    # EVAL_epoch="EVAL_epoch",
    # TRAIN_loss="TRAIN_loss",
    # EVAL_loss="EVAL_loss",
    # TEST_loss="TEST_loss",
    # GOLD_loss="GOLD_loss",
    TRAIN_rmse="RMSE train",
    EVAL_rmse="RMSE eval",
    TEST_rmse="RMSE test",
    GOLD_rmse="RMSE gold",
    # TRAIN_mse="TRAIN_mse",
    # EVAL_mse="EVAL_mse",
    # TEST_mse="TEST_mse",
    # GOLD_mse="GOLD_mse",
    # TRAIN_mae="TRAIN_mae",
    # EVAL_mae="EVAL_mae",
    # TEST_mae="TEST_mae",
    # GOLD_mae="GOLD_mae",
    # TRAIN_r2="TRAIN_r2",
    # EVAL_r2="EVAL_r2",
    # TEST_r2="TEST_r2",
    # GOLD_r2="GOLD_r2",
    # TRAIN_max_err="TRAIN_max_err",
    # EVAL_max_err="EVAL_max_err",
    # TEST_max_err="TEST_max_err",
    # GOLD_max_err="GOLD_max_err",
    # TRAIN_exp_var="TRAIN_exp_var",
    # EVAL_exp_var="EVAL_exp_var",
    # TEST_exp_var="TEST_exp_var",
    # GOLD_exp_var="GOLD_exp_var",
)

df8 = df2[cols8.keys()].copy()


# filter by fine-tuning data
datasets = ["ft0x", "ft1x", "ft2x", "ft3x", "ft4x"]
datasets = ["ft0x", "ft1x", "ft2x", "ft3x"]
df8 = df8[df8.dataset.isin(datasets)]


# filter by batch size
batch_sizes = [64]
df8 = df8[df8.batch_size.isin(batch_sizes)]


# sort rows
by=["TEST_rmse"]
by=[ "model_name", "dataset","date"]
by=["GOLD_rmse"]
ascending = True
df8 = df8.sort_values(by=by, ascending=ascending)

df8["dataset"] = df8.dataset.map({"ft0x": "FT0", "ft1x": "FT1", "ft2x": "FT2", "ft3x": "FT3", "ft4x": "FT4"})

df8.rename(
columns = cols8,
    inplace=True,
)

df8.round(4).to_excel("s7101_compare_models.xlsx")

log0.info(f"{df8.shape = }")
disp_df(df8)
\end{minted}

\begin{verbatim}
random_state
42    8
Name: count, dtype: int64I: df8.shape = (8, 15)
\end{verbatim}
\begin{verbatim}
    random_state  seed             date         Base model Fine-tuning dataset  Number of epochs  Batch size  Traininig data  Evaluation data  Test data  Gold standard  RMSE train  RMSE eval  RMSE test  RMSE gold
47            42    42  20230523T145242       roberta-base                 FT3                12          64           47842            11961        300            300    0.043505   0.052042   0.317223   0.317223
45            42    42  20230523T134342       roberta-base                 FT2                12          64           28640             7161        300            300    0.076130   0.153539   0.328255   0.328255
46            42    42  20230523T140848  bert-base-uncased                 FT3                12          64           47842            11961        300            300    0.030205   0.041089   0.331124   0.331124
43            42    42  20230523T125926       roberta-base                 FT1                12          64           22100             5525        300            300    0.074254   0.175054   0.331175   0.331175
42            42    42  20230523T124016  bert-base-uncased                 FT1                12          64           22100             5525        300            300    0.053864   0.169940   0.346672   0.346672
44            42    42  20230523T131837  bert-base-uncased                 FT2                12          64           28640             7161        300            300    0.051673   0.147735   0.347492   0.347492
41            42    42  20230523T123140       roberta-base                 FT0                12          64           10249             2563        300            300    0.176717   0.217370   0.372018   0.372018
40            42    42  20230523T122304  bert-base-uncased                 FT0                12          64           10249             2563        300            300    0.097756   0.216782   0.374942   0.374942
\end{verbatim}
\end{document}